{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proyecto II\n",
        "\n",
        "**Curso de Inteligencia Artificial**  \n",
        "**Escuela de Ingeniería en Computación**  \n",
        "**Instituto Tecnológico de Costa Rica**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## I. OBJETIVO\n",
        "\n",
        "Aplicar un experimento que permita validar la hipótesis de que al aplicar técnicas de destilado de modelos de grandes volúmenes de parámetros en modelos más pequeños se pueden resolver tareas igual de complejas pero con modelos más eficientes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## II. MODELO DE DETECCIÓN DE ANOMALÍAS\n",
        "\n",
        "Para el desarrollo de este proyecto debe usar el dataset propuesto en **MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection**. Un dataset de escenarios industriales reales con diferentes tipos de anomalías en la forma de detección de defectos en objetos o texturas.\n",
        "\n",
        "Seleccione **10 clases del dataset** las que usted más prefiera, y con este subconjunto vamos a entrenar distintos modelos para resolver un problema de detección de anomalías."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "III. MODELOS\n",
        "siguiendo la estructura de RESNET-18 para las primeras 3\n",
        "Cada modelo debe estructurar el proyecto utilizando la\n",
        "convoluciones (conv1, con2 x, con3 x) (ver Figura 1), de aca´\n",
        "librer´ıa Hydra para la gestio´n modular de configuraciones,\n",
        "en adelante coloque un clasificador (FC layer) a su gusto para\n",
        "asegurando la correcta separacio´n de hiper para´metros entre\n",
        "crear un clasificador entre las distintas clases.\n",
        "el modelo, el entrenamiento y los registros experimentales.\n",
        "Una vez disen˜ado el modelo debe proceder hacer dos\n",
        "La estructura m´ınima recomendada del proyecto es la sigu-\n",
        "variantes A y B.\n",
        "iente:\n",
        "ElmodeloAsera´ entrenadodesde0esdeciraliniciotendra´\n",
        "conf/\n",
        "pesos colocados aleatoriamente y comenzara´ su proceso de\n",
        "- config.yaml\n",
        "entrenamiento.\n",
        "- model/\n",
        "El modelo B será entrenando siguiendo un proceso de des-\n",
        "- vae.yaml\n",
        "tilado del modelo RESNET-18 siguiendo la te´cnica teacher-\n",
        "- trainer/\n",
        "student donde el modelo RESNET-18 sirve como teacher y\n",
        "- default.yaml\n",
        "el modelo B como student.\n",
        "- logger/\n",
        "Para esto debe investigar como aplicar correctamente un\n",
        "- wandb.yaml\n",
        "proceso de destilado de un modelo.\n",
        "Cada mo´dulo de configuracio´n debera´ permitir la ejecucio´n Es importante un buen disen˜o de modelo que permita\n",
        "de experimentos con distintos para´metros del modelo, tales obtener el vector de embeddings de salida de las capas\n",
        "como: convolucionales. Pues son los que luego permitira´n disen˜ar\n",
        "• Dimensio´n del espacio latente (z). el detector de anomal´ıas.\n",
        "• Cantidad de e´pocas, taman˜o de batch, o cualquier hiper- Cada modelo debe ser entrenado al menos con 3 hiper-\n",
        "parametro que requiera. pametros distintos para obtener buenos modelos y no sola-\n",
        "Adema´s debe utilizar Pytorch Ligthning para las person- mente la primera combinacio´n que obtengan.\n",
        "alizaciones de los entrenamientos y creacio´n de los modelos\n",
        "basado en las mejores pra´cticas de disen˜o de software que\n",
        "B. Modelo C - Embedding de un autoencoder\n",
        "permita una correcto disen˜o escalable. Debe crear su propia\n",
        "clase de carga de datos utilizando “LightningDataModule” y Disen˜o un modelo de autoencoder basado en U-net que re-\n",
        "su modelo utilizando “LightningModule”, aca´ debe redefinir construya las ima´genes del set de entrenamiento seleccionado\n",
        "como m´ınimo los me´todos de training step, test step, config- y tambie´n permita obtener el embedding correspondiente.\n",
        "ure optimizers. Este sera´ entrenado completamente desde 0.\n",
        "Fig.1. ArquitecturadelaredResNet-18."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IV. EVALUACIÓN DE ANOMALÍAS\n",
        "\n",
        "Una vez entrenados los modelos, se deben calcular las representaciones latentes (embeddings) de las imágenes del conjunto de validación para estimar una métrica que permita, posteriormente, identificar los datos anómalos en el conjunto de prueba.\n",
        "\n",
        "### 1) Ejemplo: Mahalanobis Distance\n",
        "\n",
        "Una manera estadística de determinar si una nueva muestra pertenece o no a la distribución de los datos normales consiste en utilizar la **distancia de Mahalanobis**.\n",
        "\n",
        "Esta métrica mide la distancia entre un vector de características (embedding) y la distribución multivariada estimada a partir de las muestras normales, considerando las correlaciones entre dimensiones.\n",
        "\n",
        "#### 1. Estimación de la distribución normal\n",
        "\n",
        "A partir del conjunto de validación o entrenamiento correspondiente a la clase sin defectos, se extraen los embeddings de cada imagen mediante el modelo previamente entrenado (para cada modelo).\n",
        "\n",
        "Cada embedding puede representarse como un vector $\\mathbf{z}_{i} \\in \\mathbb{R}^{d}$. Con todos los embeddings del conjunto normal se calcula la media $\\boldsymbol{\\mu}$ y la matriz de covarianza $\\boldsymbol{\\Sigma}$:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\mu}=\\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{z}_{i}, \\quad \\boldsymbol{\\Sigma}=\\frac{1}{N-1} \\sum_{i=1}^{N}\\left(\\mathbf{z}_{i}-\\boldsymbol{\\mu}\\right)\\left(\\mathbf{z}_{i}-\\boldsymbol{\\mu}\\right)^{T}\n",
        "$$\n",
        "\n",
        "De esta forma se modela la distribución normal como una distribución gaussiana multivariada $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, que representa los datos normales en el espacio de embeddings.\n",
        "\n",
        "#### 2. Cálculo de la distancia de Mahalanobis\n",
        "\n",
        "Para una nueva muestra con embedding $\\mathbf{z}_{\\text{test}}$, se calcula su distancia a la distribución normal.\n",
        "\n",
        "Esta distancia mide qué tan alejada se encuentra la muestra del centro de la distribución de los datos sin defectos, considerando la forma y correlaciones de dicha distribución.\n",
        "\n",
        "A partir de acá debe de averiguar como clasificar una anomalía o una clase sin defectos utilizando comparación de la distancia (e.g tomar el percentil).\n",
        "\n",
        "**Nota:** El estudiante puede implementar también otras estrategias de detección, como la distancia euclidiana, reconstrucción basada en error (reconstruction loss)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## V. MODELOS CUANTIZADOS\n",
        "\n",
        "Adicionalmente se desea hacer comparaciones de los resultados entre los modelos originales y los modelos cuantizados para hacer comparaciones de rendimiento. Para esto, convierta los **tres modelos con mejores resultados** de acuerdo a su criterio a modelos cuantizados, y realice una comparación de latencias en respuesta, tamaño, y rendimiento, incluya este análisis en su informe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VI. ANÁLISIS DE OUTLIERS MEDIANTE DBSCAN CLUSTERING\n",
        "\n",
        "Una vez identificado el mejor modelo de detección de anomalías —ya sea el clasificador CNN entrenado desde cero, su versión distilada mediante teacher–student, o el modelo autoencoder basado en U-Net— proceda a utilizar sus embeddings como insumo para realizar un análisis adicional mediante técnicas de agrupamiento no supervisado. En particular **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise), un método basado en densidad que permite identificar regiones de alta concentración en el espacio latente y, simultáneamente, detectar puntos aislados que pueden interpretarse como outliers o anomalías.\n",
        "\n",
        "Extraiga los embeddings generados por el modelo seleccionado para cada imagen del conjunto de prueba. En estos espacios latentes, las imágenes normales suelen agruparse de forma natural alrededor de regiones de alta densidad, mientras que las anomalías producen vectores que tienden a ubicarse lejos de dichas regiones. Con el fin de facilitar tanto la visualización como la separación estructural, aplique reducción de dimensionalidad con **PCA** y **t-SNE**.\n",
        "\n",
        "Una vez obtenidas las representaciones latentes reducidas aplique **DBSCAN**. Desde la perspectiva de la detección de anomalías, los puntos etiquetados por DBSCAN como ruido constituyen una indicación natural de potencial anomalía, ya que representan vectores que se encuentran en zonas de baja densidad del espacio latente.\n",
        "\n",
        "Analice los resultados desde el punto de vista visual, y cuantitativa del resultado de la clasificación de anomalías.\n",
        "\n",
        "---\n",
        "\n",
        "## RÚBRICA\n",
        "\n",
        "Si el trabajo no se encuentra debidamente ordenado y presentado siguiendo una adecuada estructura para el informe, puede ser considerado como incompleto y cualquiera de las rúbricas se puede ver afectada (ver Tabla I).\n",
        "\n",
        "### TABLA I - RÚBRICA\n",
        "\n",
        "| Criterio | Puntaje Máx. |\n",
        "| :-- | :--: |\n",
        "| Implementación de Modelo CNN Scratch y Destilado (Pytorch Lightning, Hydra y WandB) | 15 |\n",
        "| Implementación de Autoencoder U-Net (Pytorch Lightning, Hydra y WandB) | 15 |\n",
        "| Diseño experimental, múltiples entrenamientos y variación de hiperparámetros. | 10 |\n",
        "| Comparación de modelos base: reconstrucción de imágenes, progreso de validación y entrenamiento, análisis de overfitting | 10 |\n",
        "| Definición de evaluación de anomalías con embeddings | 10 |\n",
        "| Comparación de mejores modelos de detección de anomalías | 10 |\n",
        "| Comparación entre modelos originales y cuantizados (latencia, tamaño, rendimiento) | 10 |\n",
        "| Comparación de análisis de anomalías con DBSCAN: t-SNE y PCA | 15 |\n",
        "| Calidad de informe científico | 10 |\n",
        "| **Total** | **105** |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
