{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA-LqDSHRfDW"
      },
      "source": [
        "# Tarea 05 - Im√°genes Generativas\n",
        "## Detecci√≥n de Anomal√≠as en Im√°genes Industriales\n",
        "\n",
        "Este notebook implementa un sistema de detecci√≥n de anomal√≠as usando el dataset MVTec AD.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XILPaemiRfDc",
        "outputId": "ea0f4afb-2fa1-404b-cb41-3623d1efdecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (2.5.6)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.44.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n",
            "Requirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (0.15.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Instalaci√≥n de dependencias necesarias\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install matplotlib numpy scikit-learn opencv-python pillow tqdm wandb pytorch-lightning hydra-core omegaconf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSmxHlRFRfDe",
        "outputId": "de462e73-733c-4050-c703-50b5b5eb4cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZf5X-m2cq1j"
      },
      "source": [
        "### Definici√≥n de Arquitecturas de Modelos\n",
        "\n",
        "En esta secci√≥n se definen las dos arquitecturas de autoencoders que se utilizar√°n:\n",
        "- **Autoencoder Cl√°sico**: Arquitectura tradicional sin skip connections\n",
        "- **U-Net Autoencoder**: Arquitectura con skip connections para mejorar la reconstrucci√≥n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7AVTmBlcq1j",
        "outputId": "763ac1cb-abfa-4532-d034-4bcc9dcd0d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Arquitecturas de modelos definidas correctamente\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "M√≥dulo con las arquitecturas de autoencoders para detecci√≥n de anomal√≠as\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class AutoencoderClassic(nn.Module):\n",
        "    \"\"\"Autoencoder cl√°sico sin skip connections\"\"\"\n",
        "\n",
        "    def __init__(self, input_channels=3, latent_dim=128, encoder_channels=None, decoder_channels=None):\n",
        "        super(AutoencoderClassic, self).__init__()\n",
        "\n",
        "        if encoder_channels is None:\n",
        "            encoder_channels = [64, 128, 256, 512]\n",
        "        if decoder_channels is None:\n",
        "            decoder_channels = [512, 256, 128, 64]\n",
        "\n",
        "        # Encoder\n",
        "        encoder_layers = []\n",
        "        in_channels = input_channels\n",
        "\n",
        "        for out_channels in encoder_channels:\n",
        "            encoder_layers.extend([\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # Capa final del encoder\n",
        "        encoder_layers.extend([\n",
        "            nn.Conv2d(in_channels, latent_dim, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        ])\n",
        "\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_layers = []\n",
        "        in_channels = latent_dim\n",
        "\n",
        "        for out_channels in decoder_channels:\n",
        "            decoder_layers.extend([\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # Capa final del decoder\n",
        "        decoder_layers.extend([\n",
        "            nn.ConvTranspose2d(in_channels, input_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        ])\n",
        "\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"Extrae el vector latente de la entrada\"\"\"\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "\n",
        "class UNetAutoencoder(nn.Module):\n",
        "    \"\"\"Autoencoder U-net con skip connections\"\"\"\n",
        "\n",
        "    def __init__(self, input_channels=3, latent_dim=128, encoder_channels=None, decoder_channels=None):\n",
        "        super(UNetAutoencoder, self).__init__()\n",
        "\n",
        "        if encoder_channels is None:\n",
        "            encoder_channels = [64, 128, 256, 512]\n",
        "        if decoder_channels is None:\n",
        "            decoder_channels = [512, 256, 128, 64]\n",
        "\n",
        "        # Encoder con skip connections\n",
        "        self.encoder_blocks = nn.ModuleList()\n",
        "        in_channels = input_channels\n",
        "\n",
        "        for out_channels in encoder_channels:\n",
        "            self.encoder_blocks.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.BatchNorm2d(out_channels)\n",
        "                )\n",
        "            )\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # Capa bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, latent_dim, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder con skip connections\n",
        "        self.decoder_blocks = nn.ModuleList()\n",
        "        in_channels = latent_dim\n",
        "\n",
        "        # Primera capa del decoder (sin skip connection)\n",
        "        self.decoder_blocks.append(\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels, decoder_channels[0], kernel_size=4, stride=2, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(decoder_channels[0])\n",
        "            )\n",
        "        )\n",
        "        in_channels = decoder_channels[0]\n",
        "\n",
        "        # Resto de capas del decoder con skip connections\n",
        "        for i, out_channels in enumerate(decoder_channels[1:], 1):\n",
        "            # Duplicar canales de entrada para concatenar con skip connection\n",
        "            self.decoder_blocks.append(\n",
        "                nn.Sequential(\n",
        "                    nn.ConvTranspose2d(in_channels * 2, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.BatchNorm2d(out_channels)\n",
        "                )\n",
        "            )\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # Capa final\n",
        "        self.final_layer = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels * 2, input_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"Extrae el vector latente de la entrada\"\"\"\n",
        "        # Encoder - guardar skip connections\n",
        "        skip_connections = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            skip_connections.append(x)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "        return x, skip_connections\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder - guardar skip connections\n",
        "        skip_connections = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            skip_connections.append(x)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder - usar skip connections\n",
        "        for i, decoder_block in enumerate(self.decoder_blocks):\n",
        "            # Concatenar con skip connection correspondiente (en orden inverso)\n",
        "            skip = skip_connections[-(i+1)]\n",
        "            # Asegurar que las dimensiones coincidan\n",
        "            if x.shape[2:] != skip.shape[2:]:\n",
        "                x = nn.functional.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
        "            x = torch.cat([x, skip], dim=1)\n",
        "            x = decoder_block(x)\n",
        "\n",
        "        # Capa final con √∫ltimo skip connection\n",
        "        skip = skip_connections[0]\n",
        "        if x.shape[2:] != skip.shape[2:]:\n",
        "            x = nn.functional.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.final_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "print(\"‚úì Arquitecturas de modelos definidas correctamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEZhsYpGcq1k"
      },
      "source": [
        "### M√≥dulo de Pytorch Lightning\n",
        "\n",
        "En esta secci√≥n se define el m√≥dulo de Lightning que encapsula:\n",
        "- **Funciones de p√©rdida**: L1, L2, SSIM, SSIM+L1\n",
        "- **AutoencoderLightning**: Clase que gestiona el entrenamiento, validaci√≥n y logging autom√°tico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuyIe4Mxcq1l",
        "outputId": "de176cf9-6220-4b28-ae9d-226b7f9ac5e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì M√≥dulo de Lightning definido correctamente\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "M√≥dulo de Pytorch Lightning para el entrenamiento de autoencoders\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics import StructuralSimilarityIndexMeasure\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class LossFunctions:\n",
        "    \"\"\"Funciones de p√©rdida para el entrenamiento\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def l1_loss(pred, target):\n",
        "        return F.l1_loss(pred, target)\n",
        "\n",
        "    @staticmethod\n",
        "    def l2_loss(pred, target):\n",
        "        return F.mse_loss(pred, target)\n",
        "\n",
        "    @staticmethod\n",
        "    def ssim_loss(pred, target):\n",
        "        ssim = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
        "        ssim_val = ssim(pred, target)\n",
        "        return 1 - ssim_val  # SSIM es una m√©trica de similitud, convertimos a p√©rdida\n",
        "\n",
        "    @staticmethod\n",
        "    def ssim_l1_loss(pred, target, alpha=0.5):\n",
        "        ssim = LossFunctions.ssim_loss(pred, target)\n",
        "        l1 = LossFunctions.l1_loss(pred, target)\n",
        "        return alpha * ssim + (1 - alpha) * l1\n",
        "\n",
        "\n",
        "class AutoencoderLightning(pl.LightningModule):\n",
        "    \"\"\"M√≥dulo de Lightning para entrenar autoencoders\"\"\"\n",
        "\n",
        "    def __init__(self, model, learning_rate=0.001, loss_function=\"L2\", scheduler_config=None):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.learning_rate = learning_rate\n",
        "        self.loss_function = loss_function\n",
        "        self.scheduler_config = scheduler_config or {\"step_size\": 10, \"gamma\": 0.5}\n",
        "\n",
        "        # Inicializar funci√≥n de p√©rdida\n",
        "        if loss_function == \"L1\":\n",
        "            self.criterion = LossFunctions.l1_loss\n",
        "        elif loss_function == \"L2\":\n",
        "            self.criterion = LossFunctions.l2_loss\n",
        "        elif loss_function == \"SSIM\":\n",
        "            self.criterion = LossFunctions.ssim_loss\n",
        "        elif loss_function == \"SSIM_L1\":\n",
        "            self.criterion = LossFunctions.ssim_l1_loss\n",
        "        else:\n",
        "            raise ValueError(f\"Funci√≥n de p√©rdida no reconocida: {loss_function}\")\n",
        "\n",
        "        # M√©tricas\n",
        "        self.ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
        "\n",
        "        # Guardar p√©rdidas de entrenamiento\n",
        "        self.train_losses = []\n",
        "\n",
        "        # Guardar hiperpar√°metros\n",
        "        self.save_hyperparameters(ignore=['model'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x = batch\n",
        "        x_recon = self(x)\n",
        "        loss = self.criterion(x_recon, x)\n",
        "\n",
        "        # Logging\n",
        "        self.log('train/loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('train/learning_rate', self.optimizers().param_groups[0]['lr'], on_step=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # Guardar p√©rdida promedio de la √©poca\n",
        "        epoch_loss = self.trainer.callback_metrics.get('train/loss_epoch', None)\n",
        "        if epoch_loss is not None:\n",
        "            self.train_losses.append(epoch_loss.item())\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x = batch\n",
        "        x_recon = self(x)\n",
        "        loss = self.criterion(x_recon, x)\n",
        "\n",
        "        # Calcular SSIM\n",
        "        ssim_val = self.ssim_metric(x_recon, x)\n",
        "\n",
        "        # Logging\n",
        "        self.log('val/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val/ssim', ssim_val, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "            optimizer,\n",
        "            step_size=self.scheduler_config.get(\"step_size\", 10),\n",
        "            gamma=self.scheduler_config.get(\"gamma\", 0.5)\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"interval\": \"epoch\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "print(\"‚úì M√≥dulo de Lightning definido correctamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_TYqV4ecq1m"
      },
      "source": [
        "### Configuraci√≥n con Hydra\n",
        "\n",
        "En esta secci√≥n se configura el proyecto usando **Hydra** para la gesti√≥n modular de configuraciones, cumpliendo con los requisitos del enunciado.\n",
        "\n",
        "**Estructura de configuraci√≥n (seg√∫n enunciado)**:\n",
        "```\n",
        "conf/\n",
        "‚îú‚îÄ‚îÄ config.yaml          # Configuraci√≥n principal\n",
        "‚îú‚îÄ‚îÄ model/               # Configuraciones de modelos\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ autoencoder_classic.yaml\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ unet.yaml\n",
        "‚îú‚îÄ‚îÄ trainer/             # Configuraci√≥n del entrenamiento\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ default.yaml\n",
        "‚îî‚îÄ‚îÄ logger/              # Configuraci√≥n de WandB\n",
        "    ‚îî‚îÄ‚îÄ wandb.yaml\n",
        "```\n",
        "\n",
        "**Caracter√≠sticas**:\n",
        "- ‚úÖ Configuraci√≥n centralizada en archivos YAML\n",
        "- ‚úÖ Separaci√≥n modular de hiperpar√°metros (modelo, entrenamiento, logger)\n",
        "- ‚úÖ Permite cambiar hiperpar√°metros f√°cilmente usando overrides\n",
        "- ‚úÖ Integraci√≥n con WandB para tracking de experimentos\n",
        "- ‚úÖ Permite ejecutar experimentos con distintos par√°metros (dimensi√≥n latente, √©pocas, batch size, etc.)\n",
        "\n",
        "**Ubicaci√≥n de archivos**:\n",
        "- Los archivos de configuraci√≥n pueden estar en el directorio actual (`/content/conf`) o en Google Drive\n",
        "- El c√≥digo busca autom√°ticamente en ambas ubicaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAsZHklaRfDe",
        "outputId": "a5256d15-9ff7-470f-c875-776042222922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: hydra-core\n",
            "Version: 1.3.2\n",
            "Summary: A framework for elegantly configuring complex applications\n",
            "Home-page: https://github.com/facebookresearch/hydra\n",
            "Author: Omry Yadan\n",
            "Author-email: omry@fb.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: antlr4-python3-runtime, omegaconf, packaging\n",
            "Required-by: \n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core) (25.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.3)\n",
            "üîç Configurando para usar solo Google Drive...\n",
            "   Ruta base: /content/drive/MyDrive/Colab Notebooks/Tarea5-IA\n",
            "   Configuraci√≥n: /content/drive/MyDrive/Colab Notebooks/Tarea5-IA/conf\n",
            "‚úì Usando configuraci√≥n de Google Drive: /content/drive/MyDrive/Colab Notebooks/Tarea5-IA/conf\n",
            "  ‚úì Configuraci√≥n copiada temporalmente a: /content/conf/conf\n",
            "‚úì Archivo config.yaml verificado: /content/conf/conf/config.yaml\n",
            "‚úì Limpiando instancia previa de Hydra\n",
            "‚úì Directorio de trabajo configurado: /content/conf\n",
            "‚úì Verificado: /content/conf/conf/config.yaml existe\n",
            "‚úì Directorio final antes de inicializar Hydra: /content/conf\n",
            "‚úì Verificando que conf existe: True\n",
            "‚úì Verificando que config.yaml existe: True\n",
            "‚ö†Ô∏è ADVERTENCIA: El directorio de trabajo es /content/conf, no /content\n",
            "   Cambiando a /content...\n",
            "   Nuevo directorio: /content\n",
            "‚úì Inicializando Hydra con config_path='conf' desde directorio: /content\n",
            "‚úì Hydra inicializado correctamente\n",
            "‚úì Clases del notebook registradas para Hydra\n",
            "/content\n",
            "True\n",
            "/content/conf\n",
            "{'model': {'_target_': 'notebook_models.AutoencoderClassic', 'architecture': 'autoencoder_classic', 'input_channels': 3, 'latent_dim': 128, 'encoder_channels': [64, 128, 256, 512], 'decoder_channels': [512, 256, 128, 64]}, 'trainer': {'_target_': 'pytorch_lightning.Trainer', 'max_epochs': 20, 'accelerator': 'auto', 'devices': 1, 'precision': 32, 'enable_progress_bar': True, 'log_every_n_steps': 10, 'learning_rate': 0.001, 'loss_function': 'L2', 'scheduler': {'step_size': 10, 'gamma': 0.5}}, 'logger': {'_target_': 'pytorch_lightning.loggers.WandbLogger', 'project': 'tarea05-anomaly-detection', 'name': None, 'save_dir': './wandb_logs'}, 'dataset': {'path': '/content/drive/MyDrive/Colab Notebooks/Tarea5-IA/dataset', 'categories': ['cable', 'capsule', 'screw', 'transistor'], 'selected_category': 'cable', 'image_size': 128, 'batch_size': 32, 'num_workers': 2}, 'device': 'cuda'}\n",
            "Configuraci√≥n cargada con Hydra:\n",
            "model:\n",
            "  _target_: notebook_models.AutoencoderClassic\n",
            "  architecture: autoencoder_classic\n",
            "  input_channels: 3\n",
            "  latent_dim: 128\n",
            "  encoder_channels:\n",
            "  - 64\n",
            "  - 128\n",
            "  - 256\n",
            "  - 512\n",
            "  decoder_channels:\n",
            "  - 512\n",
            "  - 256\n",
            "  - 128\n",
            "  - 64\n",
            "trainer:\n",
            "  _target_: pytorch_lightning.Trainer\n",
            "  max_epochs: 20\n",
            "  accelerator: auto\n",
            "  devices: 1\n",
            "  precision: 32\n",
            "  enable_progress_bar: true\n",
            "  log_every_n_steps: 10\n",
            "  learning_rate: 0.001\n",
            "  loss_function: L2\n",
            "  scheduler:\n",
            "    step_size: 10\n",
            "    gamma: 0.5\n",
            "logger:\n",
            "  _target_: pytorch_lightning.loggers.WandbLogger\n",
            "  project: tarea05-anomaly-detection\n",
            "  name: null\n",
            "  save_dir: ./wandb_logs\n",
            "dataset:\n",
            "  path: /content/drive/MyDrive/Colab Notebooks/Tarea5-IA/dataset\n",
            "  categories:\n",
            "  - cable\n",
            "  - capsule\n",
            "  - screw\n",
            "  - transistor\n",
            "  selected_category: cable\n",
            "  image_size: 128\n",
            "  batch_size: 32\n",
            "  num_workers: 2\n",
            "device: cuda\n",
            "\n",
            "Usando dispositivo: cpu\n",
            "‚úì Ruta base de Google Drive configurada: /content/drive/MyDrive/Colab Notebooks/Tarea5-IA\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
        "import cv2\n",
        "import hydra\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "!pip show hydra-core\n",
        "!pip install --upgrade hydra-core\n",
        "\n",
        "# Los m√≥dulos ya est√°n definidos en las celdas anteriores\n",
        "# No es necesario importarlos desde archivos externos\n",
        "\n",
        "# Autenticaci√≥n de Weights & Biases\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "# Inicializar Hydra para ejecutar m√∫ltiples configuraciones\n",
        "# En Colab, usamos hydra.initialize() en lugar del decorador @hydra.main\n",
        "# IMPORTANTE: Hydra requiere que config_path sea una ruta RELATIVA, no absoluta\n",
        "# Los archivos de configuraci√≥n deben estar en el directorio de trabajo o en Google Drive\n",
        "\n",
        "# Configuraci√≥n: Usar solo Google Drive\n",
        "# Definir ruta base de Google Drive\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/Colab Notebooks/Tarea5-IA'\n",
        "drive_conf_dir = os.path.join(DRIVE_BASE_PATH, 'conf')\n",
        "\n",
        "# Crear directorio base si no existe\n",
        "os.makedirs(DRIVE_BASE_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"üîç Configurando para usar solo Google Drive...\")\n",
        "print(f\"   Ruta base: {DRIVE_BASE_PATH}\")\n",
        "print(f\"   Configuraci√≥n: {drive_conf_dir}\")\n",
        "\n",
        "# Verificar si existe en Google Drive\n",
        "config_file_drive = os.path.join(drive_conf_dir, 'config.yaml')\n",
        "\n",
        "if os.path.exists(config_file_drive):\n",
        "    # Usar configuraci√≥n de Google Drive\n",
        "    print(f\"‚úì Usando configuraci√≥n de Google Drive: {drive_conf_dir}\")\n",
        "    # Copiar temporalmente al directorio actual para Hydra (requiere ruta relativa)\n",
        "    import shutil\n",
        "    current_dir = os.getcwd()\n",
        "    conf_dir_temp = os.path.join(current_dir, 'conf')\n",
        "\n",
        "    # Limpiar directorio temporal si existe\n",
        "    if os.path.exists(conf_dir_temp):\n",
        "        shutil.rmtree(conf_dir_temp)\n",
        "\n",
        "    # Copiar configuraci√≥n de Google Drive al directorio temporal\n",
        "    shutil.copytree(drive_conf_dir, conf_dir_temp)\n",
        "    print(f\"  ‚úì Configuraci√≥n copiada temporalmente a: {conf_dir_temp}\")\n",
        "    config_path_for_hydra = 'conf'  # Ruta relativa\n",
        "else:\n",
        "    # Si no existe, crear los archivos de configuraci√≥n b√°sicos en Google Drive\n",
        "    print(f\"‚ö†Ô∏è No se encontraron archivos de configuraci√≥n en Google Drive\")\n",
        "    print(f\"   Creando estructura y archivos de configuraci√≥n b√°sicos en: {drive_conf_dir}\")\n",
        "\n",
        "    # Crear estructura de directorios en Google Drive\n",
        "    os.makedirs(drive_conf_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(drive_conf_dir, 'model'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(drive_conf_dir, 'trainer'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(drive_conf_dir, 'logger'), exist_ok=True)\n",
        "\n",
        "    # Crear archivo config.yaml b√°sico\n",
        "    config_yaml_content = f\"\"\"# Configuraci√≥n principal del proyecto\n",
        "defaults:\n",
        "  - model: autoencoder_classic\n",
        "  - trainer: default\n",
        "  - logger: wandb\n",
        "\n",
        "# Configuraci√≥n del dataset\n",
        "dataset:\n",
        "  path: \"{DRIVE_BASE_PATH}/dataset\"\n",
        "  categories: [\"cable\", \"capsule\", \"screw\", \"transistor\"]\n",
        "  selected_category: \"cable\"\n",
        "  image_size: 128\n",
        "  batch_size: 32\n",
        "  num_workers: 2\n",
        "\n",
        "# Configuraci√≥n del modelo\n",
        "# Los par√°metros espec√≠ficos del modelo est√°n en conf/model/\n",
        "\n",
        "# Configuraci√≥n del entrenamiento\n",
        "trainer:\n",
        "  max_epochs: 20\n",
        "  learning_rate: 0.001\n",
        "  loss_function: \"L2\"\n",
        "  scheduler:\n",
        "    step_size: 10\n",
        "    gamma: 0.5\n",
        "\n",
        "# Configuraci√≥n del logger\n",
        "logger:\n",
        "  project: \"tarea05-anomaly-detection\"\n",
        "  name: null\n",
        "\n",
        "# Configuraci√≥n del dispositivo\n",
        "device: \"cuda\"\n",
        "\"\"\"\n",
        "\n",
        "    with open(config_file_drive, 'w', encoding='utf-8') as f:\n",
        "        f.write(config_yaml_content)\n",
        "    print(f\"  ‚úì Creado: config.yaml\")\n",
        "\n",
        "    # Crear archivo autoencoder_classic.yaml\n",
        "    # NOTA: Las clases est√°n definidas en el notebook y se registran como notebook_models\n",
        "    autoencoder_yaml = \"\"\"# Configuraci√≥n del autoencoder cl√°sico\n",
        "# NOTA: _target_ apunta a la clase registrada en notebook_models\n",
        "_target_: notebook_models.AutoencoderClassic\n",
        "\n",
        "architecture: \"autoencoder_classic\"\n",
        "\n",
        "input_channels: 3\n",
        "latent_dim: 128\n",
        "\n",
        "encoder_channels: [64, 128, 256, 512]\n",
        "decoder_channels: [512, 256, 128, 64]\n",
        "\"\"\"\n",
        "    with open(os.path.join(drive_conf_dir, 'model', 'autoencoder_classic.yaml'), 'w', encoding='utf-8') as f:\n",
        "        f.write(autoencoder_yaml)\n",
        "    print(f\"  ‚úì Creado: model/autoencoder_classic.yaml\")\n",
        "\n",
        "    # Crear archivo unet.yaml\n",
        "    unet_yaml = \"\"\"# Configuraci√≥n del autoencoder U-net con skip connections\n",
        "# NOTA: _target_ apunta a la clase registrada en notebook_models\n",
        "_target_: notebook_models.UNetAutoencoder\n",
        "\n",
        "architecture: \"unet\"\n",
        "\n",
        "input_channels: 3\n",
        "latent_dim: 128\n",
        "\n",
        "encoder_channels: [64, 128, 256, 512]\n",
        "decoder_channels: [512, 256, 128, 64]\n",
        "\"\"\"\n",
        "    with open(os.path.join(drive_conf_dir, 'model', 'unet.yaml'), 'w', encoding='utf-8') as f:\n",
        "        f.write(unet_yaml)\n",
        "    print(f\"  ‚úì Creado: model/unet.yaml\")\n",
        "\n",
        "    # Crear archivo default.yaml para trainer\n",
        "    trainer_yaml = \"\"\"# Configuraci√≥n del entrenador\n",
        "max_epochs: 20\n",
        "learning_rate: 0.001\n",
        "loss_function: \"L2\"\n",
        "scheduler:\n",
        "  step_size: 10\n",
        "  gamma: 0.5\n",
        "\"\"\"\n",
        "    with open(os.path.join(drive_conf_dir, 'trainer', 'default.yaml'), 'w', encoding='utf-8') as f:\n",
        "        f.write(trainer_yaml)\n",
        "    print(f\"  ‚úì Creado: trainer/default.yaml\")\n",
        "\n",
        "    # Crear archivo wandb.yaml\n",
        "    wandb_yaml = f\"\"\"# Configuraci√≥n de WandB\n",
        "project: \"tarea05-anomaly-detection\"\n",
        "name: null\n",
        "save_dir: \"{DRIVE_BASE_PATH}/wandb_logs\"\n",
        "\"\"\"\n",
        "    with open(os.path.join(drive_conf_dir, 'logger', 'wandb.yaml'), 'w', encoding='utf-8') as f:\n",
        "        f.write(wandb_yaml)\n",
        "    print(f\"  ‚úì Creado: logger/wandb.yaml\")\n",
        "\n",
        "    print(f\"‚úì Estructura de configuraci√≥n creada en: {drive_conf_dir}\")\n",
        "\n",
        "    # Copiar temporalmente al directorio actual para Hydra\n",
        "    import shutil\n",
        "    current_dir = os.getcwd()\n",
        "    conf_dir_temp = os.path.join(current_dir, 'conf')\n",
        "    if os.path.exists(conf_dir_temp):\n",
        "        shutil.rmtree(conf_dir_temp)\n",
        "    shutil.copytree(drive_conf_dir, conf_dir_temp)\n",
        "    print(f\"  ‚úì Configuraci√≥n copiada temporalmente a: {conf_dir_temp}\")\n",
        "    config_path_for_hydra = 'conf'  # Ruta relativa\n",
        "\n",
        "# Verificar que el archivo config.yaml existe antes de inicializar Hydra\n",
        "# Usar el archivo temporal para Hydra\n",
        "# IMPORTANTE: Definir current_dir ANTES de usarlo\n",
        "current_dir = os.getcwd()\n",
        "conf_dir_temp = os.path.join(current_dir, 'conf')\n",
        "config_file = os.path.join(conf_dir_temp, 'config.yaml')\n",
        "\n",
        "if not os.path.exists(config_file):\n",
        "    raise FileNotFoundError(\n",
        "        f\"‚ùå ERROR: No se pudo crear o encontrar config.yaml\\n\"\n",
        "        f\"Se esperaba en: {config_file}\\n\"\n",
        "        f\"Directorio actual: {current_dir}\\n\"\n",
        "        f\"Por favor, verifica que los archivos est√©n en Google Drive: {drive_conf_dir}\"\n",
        "    )\n",
        "\n",
        "print(f\"‚úì Archivo config.yaml verificado: {config_file}\")\n",
        "\n",
        "# Limpiar Hydra si ya est√° inicializado (√∫til si se ejecuta la celda m√∫ltiples veces)\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "if GlobalHydra.instance().is_initialized():\n",
        "    GlobalHydra.instance().clear()\n",
        "    print(\"‚úì Limpiando instancia previa de Hydra\")\n",
        "\n",
        "# IMPORTANTE: Asegurarnos de estar en el directorio correcto ANTES de inicializar Hydra\n",
        "# Hydra usa el directorio de trabajo actual para buscar la configuraci√≥n\n",
        "# Si no estamos en el directorio correcto, Hydra buscar√° en /tmp\n",
        "os.chdir(current_dir)\n",
        "actual_dir = os.getcwd()\n",
        "print(f\"‚úì Directorio de trabajo configurado: {actual_dir}\")\n",
        "\n",
        "# Verificar que el directorio conf existe en el directorio actual\n",
        "if not os.path.exists(conf_dir_temp):\n",
        "    raise FileNotFoundError(\n",
        "        f\"‚ùå ERROR: No se encontr√≥ el directorio conf en {actual_dir}\\n\"\n",
        "        f\"Se esperaba: {conf_dir_temp}\\n\"\n",
        "        f\"Por favor, verifica que los archivos de configuraci√≥n est√©n en Google Drive: {drive_conf_dir}\"\n",
        "    )\n",
        "\n",
        "# Verificar que config.yaml existe\n",
        "if not os.path.exists(config_file):\n",
        "    raise FileNotFoundError(\n",
        "        f\"‚ùå ERROR: No se encontr√≥ config.yaml en {conf_dir_temp}\\n\"\n",
        "        f\"Por favor, verifica que los archivos de configuraci√≥n est√©n en Google Drive: {drive_conf_dir}\"\n",
        "    )\n",
        "\n",
        "print(f\"‚úì Verificado: {config_file} existe\")\n",
        "\n",
        "# Inicializar Hydra con ruta relativa\n",
        "# Hydra requiere que config_path sea relativa al directorio de trabajo actual\n",
        "# IMPORTANTE:\n",
        "# - config_path debe ser 'conf' (sin barra inicial, sin ruta absoluta)\n",
        "# - El directorio conf debe estar en el directorio de trabajo actual\n",
        "# - Hydra buscar√° en: <directorio_actual>/conf/\n",
        "\n",
        "# Verificar una vez m√°s que estamos en el directorio correcto\n",
        "final_dir = os.getcwd()\n",
        "print(f\"‚úì Directorio final antes de inicializar Hydra: {final_dir}\")\n",
        "print(f\"‚úì Verificando que conf existe: {os.path.exists(conf_dir_temp)}\")\n",
        "print(f\"‚úì Verificando que config.yaml existe: {os.path.exists(config_file)}\")\n",
        "\n",
        "# Inicializar Hydra\n",
        "# IMPORTANTE: Hydra puede cambiar el directorio de trabajo cuando se inicializa\n",
        "# Para evitar que busque en /tmp, necesitamos asegurarnos de que:\n",
        "# 1. El directorio de trabajo actual sea /content (donde est√° conf/)\n",
        "# 2. El directorio conf/ est√© en el directorio de trabajo actual\n",
        "# 3. Usar job_name para evitar que Hydra cree directorios temporales\n",
        "\n",
        "# Verificar que estamos en /content\n",
        "if os.getcwd() != '/content':\n",
        "    print(f\"‚ö†Ô∏è ADVERTENCIA: El directorio de trabajo es {os.getcwd()}, no /content\")\n",
        "    print(f\"   Cambiando a /content...\")\n",
        "    os.chdir('/content')\n",
        "    print(f\"   Nuevo directorio: {os.getcwd()}\")\n",
        "\n",
        "# Verificar nuevamente que conf existe\n",
        "if not os.path.exists('/content/conf'):\n",
        "    print(f\"‚ùå ERROR: No se encontr√≥ /content/conf\")\n",
        "    print(f\"   Copiando desde Google Drive...\")\n",
        "    import shutil\n",
        "    if os.path.exists(drive_conf_dir):\n",
        "        if os.path.exists('/content/conf'):\n",
        "            shutil.rmtree('/content/conf')\n",
        "        shutil.copytree(drive_conf_dir, '/content/conf')\n",
        "        print(f\"   ‚úì Copiado a /content/conf\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"No se encontr√≥ {drive_conf_dir}\")\n",
        "\n",
        "try:\n",
        "    print(f\"‚úì Inicializando Hydra con config_path='{config_path_for_hydra}' desde directorio: {os.getcwd()}\")\n",
        "    # Usar job_name para evitar que Hydra cree directorios temporales\n",
        "    hydra.initialize(config_path=config_path_for_hydra, version_base=None, job_name=\"notebook\")\n",
        "    print(\"‚úì Hydra inicializado correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error al inicializar Hydra: {e}\")\n",
        "    print(f\"   Directorio actual: {os.getcwd()}\")\n",
        "    print(f\"   Conf dir esperado: /content/conf\")\n",
        "    print(f\"   Conf dir existe: {os.path.exists('/content/conf')}\")\n",
        "    if os.path.exists('/content/conf'):\n",
        "        print(f\"   Contenido de /content/conf: {os.listdir('/content/conf')}\")\n",
        "    raise\n",
        "\n",
        "# IMPORTANTE: Registrar las clases del notebook en el resolver de Hydra\n",
        "# Esto permite que instantiate() encuentre las clases definidas en el notebook\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "from hydra.core.config_store import ConfigStore\n",
        "\n",
        "# Crear un m√≥dulo temporal para registrar las clases\n",
        "import sys\n",
        "import types\n",
        "\n",
        "# Crear un m√≥dulo temporal 'notebook_models' que contenga las clases\n",
        "notebook_models = types.ModuleType('notebook_models')\n",
        "notebook_models.AutoencoderClassic = AutoencoderClassic\n",
        "notebook_models.UNetAutoencoder = UNetAutoencoder\n",
        "sys.modules['notebook_models'] = notebook_models\n",
        "\n",
        "# Actualizar los archivos YAML para usar notebook_models\n",
        "# Actualizar tanto en Google Drive como en el directorio temporal\n",
        "for yaml_file in [os.path.join(drive_conf_dir, 'model', 'autoencoder_classic.yaml'),\n",
        "                  os.path.join(drive_conf_dir, 'model', 'unet.yaml'),\n",
        "                  os.path.join(conf_dir_temp, 'model', 'autoencoder_classic.yaml'),\n",
        "                  os.path.join(conf_dir_temp, 'model', 'unet.yaml')]:\n",
        "    if os.path.exists(yaml_file):\n",
        "        with open(yaml_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        # Reemplazar _target_ si apunta a AutoencoderClassic o UNetAutoencoder directamente\n",
        "        if '_target_: AutoencoderClassic' in content or '_target_: UNetAutoencoder' in content:\n",
        "            content = content.replace('_target_: AutoencoderClassic', '_target_: notebook_models.AutoencoderClassic')\n",
        "            content = content.replace('_target_: UNetAutoencoder', '_target_: notebook_models.UNetAutoencoder')\n",
        "            with open(yaml_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            print(f\"‚úì Actualizado: {os.path.basename(yaml_file)}\")\n",
        "\n",
        "print(\"‚úì Clases del notebook registradas para Hydra\")\n",
        "\n",
        "# Componer la configuraci√≥n (permite override desde par√°metros)\n",
        "\n",
        "print(os.getcwd())\n",
        "try:\n",
        "  print(os.path.exists('/content/conf/config.yaml'))\n",
        "  os.chdir('/content/conf')\n",
        "  print(os.getcwd())\n",
        "  cfg = hydra.compose(config_name=\"config\")\n",
        "except Exception as e:\n",
        "  print(f\"‚ùå Error al cargar la configuraci√≥n: {e}\")\n",
        "  raise\n",
        "print(cfg)\n",
        "\n",
        "# Ejemplos de c√≥mo usar overrides para cambiar configuraciones:\n",
        "#\n",
        "# 1. Cambiar arquitectura a U-net:\n",
        "#    cfg = hydra.compose(config_name=\"config\", overrides=[\"model=unet\"])\n",
        "#\n",
        "# 2. Cambiar funci√≥n de p√©rdida:\n",
        "#    cfg = hydra.compose(config_name=\"config\", overrides=[\"trainer.loss_function=SSIM\"])\n",
        "#\n",
        "# 3. Cambiar learning rate:\n",
        "#    cfg = hydra.compose(config_name=\"config\", overrides=[\"trainer.learning_rate=0.0005\"])\n",
        "#\n",
        "# 4. Cambiar dimensi√≥n del espacio latente:\n",
        "#    cfg = hydra.compose(config_name=\"config\", overrides=[\"model.latent_dim=256\"])\n",
        "#\n",
        "# 5. Cambiar categor√≠a del dataset:\n",
        "#    cfg = hydra.compose(config_name=\"config\", overrides=[\"dataset.selected_category=capsule\"])\n",
        "#\n",
        "# 6. M√∫ltiples overrides:\n",
        "#    cfg = hydra.compose(config_name=\"config\", overrides=[\"model=unet\", \"trainer.loss_function=SSIM_L1\", \"trainer.max_epochs=30\"])\n",
        "\n",
        "print(\"Configuraci√≥n cargada con Hydra:\")\n",
        "print(OmegaConf.to_yaml(cfg))\n",
        "\n",
        "# Extraer valores de configuraci√≥n\n",
        "DATASET_PATH = cfg.dataset.path\n",
        "SELECTED_CATEGORY = cfg.dataset.selected_category\n",
        "IMAGE_SIZE = cfg.dataset.image_size\n",
        "BATCH_SIZE = cfg.dataset.batch_size\n",
        "NUM_WORKERS = cfg.dataset.num_workers\n",
        "\n",
        "# Configurar dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Usando dispositivo: {device}')\n",
        "\n",
        "# La variable DRIVE_BASE_PATH est√° disponible para todo el notebook\n",
        "# Se usa para guardar modelos, im√°genes, resultados, etc. en Google Drive\n",
        "print(f'‚úì Ruta base de Google Drive configurada: {DRIVE_BASE_PATH}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-Ylf5VU4XJ3",
        "outputId": "8fb618aa-24ae-40c0-d611-77dfddddb1fb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7St3OVrvRfDe"
      },
      "source": [
        "## 1. Carga y Preprocesamiento de Datos\n",
        "\n",
        "En esta secci√≥n se realiza:\n",
        "- **Carga del dataset MVTec AD**: Se cargan las rutas de las im√°genes de entrenamiento y prueba\n",
        "- **Definici√≥n de transformaciones**: Resize a 128x128, normalizaci√≥n y conversi√≥n a tensores\n",
        "- **Creaci√≥n de DataLoaders**: Preparaci√≥n de los datos para el entrenamiento con divisi√≥n train/validation (80-20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4pFqCaYDRfDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ea4c20-a17e-4a15-ddc3-2393c4e78f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Im√°genes de entrenamiento: 224\n",
            "Im√°genes de prueba: 150\n"
          ]
        }
      ],
      "source": [
        "class AnomalyDataset(Dataset):\n",
        "    \"\"\"Dataset para cargar im√°genes de entrenamiento y prueba\"\"\"\n",
        "\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "def load_dataset_paths(category_path, split='train'):\n",
        "    \"\"\"Carga las rutas de las im√°genes del dataset\"\"\"\n",
        "    paths = []\n",
        "    split_path = os.path.join(category_path, split)\n",
        "\n",
        "    if split == 'train':\n",
        "        # Solo im√°genes 'good' en entrenamiento\n",
        "        good_path = os.path.join(split_path, 'good')\n",
        "        if os.path.exists(good_path):\n",
        "            for img_file in os.listdir(good_path):\n",
        "                if img_file.endswith('.png'):\n",
        "                    paths.append(os.path.join(good_path, img_file))\n",
        "    else:\n",
        "        # En test, cargar todas las clases (good y defectos)\n",
        "        if os.path.exists(split_path):\n",
        "            for class_name in os.listdir(split_path):\n",
        "                class_path = os.path.join(split_path, class_name)\n",
        "                if os.path.isdir(class_path):\n",
        "                    for img_file in os.listdir(class_path):\n",
        "                        if img_file.endswith('.png'):\n",
        "                            paths.append(os.path.join(class_path, img_file))\n",
        "\n",
        "    return paths\n",
        "\n",
        "# Cargar rutas del dataset\n",
        "category_path = os.path.join(DATASET_PATH, SELECTED_CATEGORY)\n",
        "train_paths = load_dataset_paths(category_path, split='train')\n",
        "test_paths = load_dataset_paths(category_path, split='test')\n",
        "\n",
        "print(f'Im√°genes de entrenamiento: {len(train_paths)}')\n",
        "print(f'Im√°genes de prueba: {len(test_paths)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "XsUYNRV6RfDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76225cc6-e164-4b44-fcb5-aea096c59998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches de entrenamiento: 6\n",
            "Batches de validaci√≥n: 2\n",
            "Batches de prueba: 5\n"
          ]
        }
      ],
      "source": [
        "# Transformaciones de datos (usando configuraci√≥n de Hydra)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Crear datasets\n",
        "train_dataset = AnomalyDataset(train_paths, transform=train_transform)\n",
        "test_dataset = AnomalyDataset(test_paths, transform=test_transform)\n",
        "\n",
        "# Crear dataloaders (usando configuraci√≥n de Hydra)\n",
        "# Dividir el set de entrenamiento en train y validation (80-20) para WandB\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset_split, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset_split, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "print(f'Batches de entrenamiento: {len(train_loader)}')\n",
        "print(f'Batches de validaci√≥n: {len(val_loader)}')\n",
        "print(f'Batches de prueba: {len(test_loader)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUxrqKI8RfDf"
      },
      "source": [
        "## 2.2. Definici√≥n del Modelo - Autoencoder Cl√°sico y U-net (Experimento Individual)\n",
        "\n",
        "Esta secci√≥n permite ejecutar **un solo experimento** de forma manual.\n",
        "\n",
        "**Pasos**:\n",
        "1. Instanciar el modelo usando Hydra (permite cambiar arquitectura con overrides)\n",
        "2. Crear el m√≥dulo Lightning con la funci√≥n de p√©rdida especificada\n",
        "3. Configurar WandB logger y callbacks\n",
        "\n",
        "**Nota**: Si ejecutaste la celda de automatizaci√≥n (2.1), puedes saltar esta secci√≥n.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7Ql9WeQcq1p"
      },
      "source": [
        "## 2.1. Ejecuci√≥n Automatizada de Experimentos (Opcional)\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANTE**: Esta celda debe ejecutarse DESPU√âS de haber definido las funciones `AnomalyDataset`, `load_dataset_paths` y `get_anomaly_labels` en las celdas anteriores.\n",
        "\n",
        "Esta celda ejecuta autom√°ticamente **todos los experimentos requeridos**:\n",
        "- **2 arquitecturas**: Autoencoder Cl√°sico y U-net\n",
        "- **4 funciones de p√©rdida**: L1, L2, SSIM, SSIM_L1\n",
        "- **Total: 8 experimentos**\n",
        "\n",
        "**Proceso automatizado**:\n",
        "1. Itera sobre todas las combinaciones de arquitectura y funci√≥n de p√©rdida\n",
        "2. Entrena cada modelo usando Pytorch Lightning\n",
        "3. Eval√∫a el modelo y calcula m√©tricas (AUC-ROC, Average Precision)\n",
        "4. Registra todo en WandB\n",
        "5. Genera un resumen comparativo al final\n",
        "\n",
        "**Nota**: Si prefieres ejecutar un solo experimento, puedes saltar esta celda y usar la secci√≥n 2.2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "DEOFWvvfcq1p"
      },
      "outputs": [],
      "source": [
        "# Ejecuci√≥n automatizada de todos los experimentosimport pandas as pdfrom datetime import datetimefrom pytorch_lightning import Trainerfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitorfrom pytorch_lightning.loggers import WandbLoggerfrom hydra.utils import instantiate# Configuraci√≥n de experimentosARCHITECTURES = [\"autoencoder_classic\", \"unet\"]LOSS_FUNCTIONS = [\"L1\", \"L2\", \"SSIM\", \"SSIM_L1\"]# Almacenar resultados de todos los experimentosexperiment_results = []print(\"=\" * 80)print(\"INICIANDO EJECUCI√ìN AUTOMATIZADA DE EXPERIMENTOS\")print(\"=\" * 80)print(f\"Total de experimentos: {len(ARCHITECTURES) * len(LOSS_FUNCTIONS)}\")print(f\"Arquitecturas: {ARCHITECTURES}\")print(f\"Funciones de p√©rdida: {LOSS_FUNCTIONS}\")print(\"=\" * 80)# Iterar sobre todas las combinacionesfor arch_idx, architecture in enumerate(ARCHITECTURES):    for loss_idx, loss_function in enumerate(LOSS_FUNCTIONS):        exp_num = arch_idx * len(LOSS_FUNCTIONS) + loss_idx + 1        total_exps = len(ARCHITECTURES) * len(LOSS_FUNCTIONS)                print(f\"\\n{'='*80}\")        print(f\"EXPERIMENTO {exp_num}/{total_exps}\")        print(f\"Arquitectura: {architecture}\")        print(f\"Funci√≥n de p√©rdida: {loss_function}\")        print(f\"{'='*80}\\n\")                # Componer configuraci√≥n con overrides        cfg = hydra.compose(            config_name=\"config\",            overrides=[                f\"model={architecture}\",                f\"trainer.loss_function={loss_function}\"            ]        )                # Extraer valores de configuraci√≥n        DATASET_PATH = cfg.dataset.path        SELECTED_CATEGORY = cfg.dataset.selected_category        IMAGE_SIZE = cfg.dataset.image_size        BATCH_SIZE = cfg.dataset.batch_size        NUM_WORKERS = cfg.dataset.num_workers                # Cargar rutas del dataset        category_path = os.path.join(DATASET_PATH, SELECTED_CATEGORY)        train_paths = load_dataset_paths(category_path, split='train')        test_paths = load_dataset_paths(category_path, split='test')                # Crear transformaciones        train_transform = transforms.Compose([            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),            transforms.ToTensor(),            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])        ])                test_transform = transforms.Compose([            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),            transforms.ToTensor(),            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])        ])                # Crear datasets y dataloaders        train_dataset = AnomalyDataset(train_paths, transform=train_transform)        test_dataset = AnomalyDataset(test_paths, transform=test_transform)                # Dividir train en train y validation (80-20)        from torch.utils.data import random_split        train_size = int(0.8 * len(train_dataset))        val_size = len(train_dataset) - train_size        train_dataset_split, val_dataset = random_split(train_dataset, [train_size, val_size])                train_loader = DataLoader(train_dataset_split, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)                # Instanciar modelo        base_model = instantiate(cfg.model)        base_model = base_model.to(device)                # Crear m√≥dulo Lightning        lightning_model = AutoencoderLightning(            model=base_model,            learning_rate=cfg.trainer.learning_rate,            loss_function=cfg.trainer.loss_function,            scheduler_config=cfg.trainer.scheduler        )                # Configurar logger de WandB para este experimento        wandb_logger = WandbLogger(            project=cfg.logger.project,            name=f\"{architecture}-{loss_function}-{SELECTED_CATEGORY}\",            config=OmegaConf.to_container(cfg, resolve=True),            reinit=True        )                # Callbacks        checkpoint_callback = ModelCheckpoint(            monitor='train/loss_epoch',            checkpoint_dir = os.path.join(DRIVE_BASE_PATH, 'checkpoints', r'{architecture}-{loss_function}')        os.makedirs(checkpoint_dir, exist_ok=True)        dirpath=checkpoint_dir,            filename=f'{architecture}-{loss_function}-{{epoch:02d}}-{{train/loss_epoch:.4f}}',            save_top_k=1,            mode='min'        )                lr_monitor = LearningRateMonitor(logging_interval='step')                # Crear Trainer        trainer = Trainer(            max_epochs=cfg.trainer.max_epochs,            accelerator='auto',            devices=1,            logger=wandb_logger,            callbacks=[checkpoint_callback, lr_monitor],            log_every_n_steps=10,            enable_progress_bar=True        )                # Entrenar con validaci√≥n        print(f\"\\nIniciando entrenamiento...\")        trainer.fit(lightning_model, train_loader, val_loader)                # Obtener p√©rdidas de entrenamiento        train_losses = lightning_model.train_losses if hasattr(lightning_model, 'train_losses') else []        final_train_loss = train_losses[-1] if train_losses else None                # Evaluar        print(f\"\\nEvaluando modelo...\")        lightning_model.model.eval()        anomaly_scores = []                with torch.no_grad():            for images in test_loader:                images = images.to(device)                reconstructed = lightning_model.model(images)                mse = torch.mean((images - reconstructed) ** 2, dim=(1, 2, 3))                anomaly_scores.extend(mse.cpu().numpy())                anomaly_scores = np.array(anomaly_scores)                # Obtener etiquetas        test_labels = get_anomaly_labels(test_paths, category_path)                # Calcular m√©tricas        auc_score = roc_auc_score(test_labels, anomaly_scores)        ap_score = average_precision_score(test_labels, anomaly_scores)                # Guardar resultados        result = {            'experiment': exp_num,            'architecture': architecture,            'loss_function': loss_function,            'category': SELECTED_CATEGORY,            'final_train_loss': final_train_loss,            'auc_roc': auc_score,            'average_precision': ap_score,            'min_score': float(anomaly_scores.min()),            'max_score': float(anomaly_scores.max()),            'mean_score': float(anomaly_scores.mean()),            'std_score': float(anomaly_scores.std())        }        experiment_results.append(result)                # Loggear m√©tricas finales en wandb        wandb.log({            \"eval/auc_roc\": auc_score,            \"eval/average_precision\": ap_score,            \"eval/final_train_loss\": final_train_loss if final_train_loss else 0.0        })                # Finalizar wandb run        wandb.finish()                print(f\"\\n‚úì Experimento {exp_num}/{total_exps} completado\")        print(f\"  AUC-ROC: {auc_score:.4f}\")        print(f\"  Average Precision: {ap_score:.4f}\")        print(f\"  P√©rdida final: {final_train_loss:.4f if final_train_loss else 'N/A'}\")                # Limpiar memoria        del lightning_model        del base_model        del trainer        if torch.cuda.is_available():            torch.cuda.empty_cache()# Crear DataFrame con resultadosresults_df = pd.DataFrame(experiment_results)# Guardar resultadosresults_path = os.path.join(DRIVE_BASE_PATH, 'resultados_experimentos.csv')results_df.to_csv(results_path, index=False)print(f\"\\n{'='*80}\")print(\"TODOS LOS EXPERIMENTOS COMPLETADOS\")print(f\"{'='*80}\")print(f\"\\nResultados guardados en: {results_path}\")print(\"\\nResumen de resultados:\")print(results_df.to_string(index=False))# Crear tabla comparativaprint(f\"\\n{'='*80}\")print(\"TABLA COMPARATIVA DE RESULTADOS\")print(f\"{'='*80}\")comparison = results_df.pivot_table(    index='architecture',    columns='loss_function',    values=['auc_roc', 'average_precision'],    aggfunc='first')print(comparison)# Guardar tabla comparativacomparison_path = os.path.join(DRIVE_BASE_PATH, 'comparacion_experimentos.csv')comparison.to_csv(comparison_path)print(f\"\\nTabla comparativa guardada en: {comparison_path}\")# Visualizar comparaci√≥nfig, axes = plt.subplots(1, 2, figsize=(15, 6))# Gr√°fico de AUC-ROCauc_pivot = results_df.pivot_table(    index='architecture',    columns='loss_function',    values='auc_roc',    aggfunc='first')auc_pivot.plot(kind='bar', ax=axes[0], rot=0)axes[0].set_title('Comparaci√≥n de AUC-ROC por Arquitectura y Funci√≥n de P√©rdida')axes[0].set_ylabel('AUC-ROC')axes[0].legend(title='Funci√≥n de P√©rdida')axes[0].grid(True, alpha=0.3)# Gr√°fico de Average Precisionap_pivot = results_df.pivot_table(    index='architecture',    columns='loss_function',    values='average_precision',    aggfunc='first')ap_pivot.plot(kind='bar', ax=axes[1], rot=0)axes[1].set_title('Comparaci√≥n de Average Precision por Arquitectura y Funci√≥n de P√©rdida')axes[1].set_ylabel('Average Precision')axes[1].legend(title='Funci√≥n de P√©rdida')axes[1].grid(True, alpha=0.3)plt.tight_layout()comparison_plot_path = os.path.join(DRIVE_BASE_PATH, 'comparacion_grafica.png')plt.savefig(comparison_plot_path)plt.show()print(f\"\\n{'='*80}\")print(\"AN√ÅLISIS COMPLETO\")print(f\"{'='*80}\")print(\"\\nMejor resultado por m√©trica:\")best_auc = results_df.loc[results_df['auc_roc'].idxmax()]print(f\"Mejor AUC-ROC: Arquitectura={best_auc['architecture']}, Loss={best_auc['loss_function']}, AUC={best_auc['auc_roc']:.4f}\")best_ap = results_df.loc[results_df['average_precision'].idxmax()]print(f\"Mejor Average Precision: Arquitectura={best_ap['architecture']}, Loss={best_ap['loss_function']}, AP={best_ap['average_precision']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PJVBWiAgRfDg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "10daa50a-93ce-4a9b-a5dc-b87dc912fa3b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InstantiationException",
          "evalue": "Error in call to target '__main__.AutoencoderClassic':\nTypeError(\"AutoencoderClassic.__init__() got an unexpected keyword argument 'architecture'\")\nfull_key: model",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/hydra/_internal/instantiate/_instantiate2.py\u001b[0m in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_target_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: AutoencoderClassic.__init__() got an unexpected keyword argument 'architecture'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-716886865.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Instanciar el modelo autom√°ticamente desde la configuraci√≥n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Esto usa el _target_ y par√°metros definidos en conf/model/autoencoder_classic.yaml o conf/model/unet.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Modelo instanciado: {cfg.model._target_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/hydra/_internal/instantiate/_instantiate2.py\u001b[0m in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0m_partial_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARTIAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         return instantiate_node(\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_recursive_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_convert_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_partial_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/hydra/_internal/instantiate/_instantiate2.py\u001b[0m in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_target_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;31m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/hydra/_internal/instantiate/_instantiate2.py\u001b[0m in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfull_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\nfull_key: {full_key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInstantiationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target '__main__.AutoencoderClassic':\nTypeError(\"AutoencoderClassic.__init__() got an unexpected keyword argument 'architecture'\")\nfull_key: model"
          ]
        }
      ],
      "source": [
        "# Crear modelo usando instanciaci√≥n autom√°tica de Hydra\n",
        "# Hydra instanciar√° autom√°ticamente el modelo seg√∫n la configuraci√≥n en conf/model/\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "# Instanciar el modelo autom√°ticamente desde la configuraci√≥n\n",
        "# Esto usa el _target_ y par√°metros definidos en conf/model/autoencoder_classic.yaml o conf/model/unet.yaml\n",
        "base_model = instantiate(cfg.model)\n",
        "\n",
        "print(f\"Modelo instanciado: {cfg.model._target_}\")\n",
        "print(f\"Par√°metros del modelo: {sum(p.numel() for p in base_model.parameters())}\")\n",
        "\n",
        "# Crear m√≥dulo Lightning con la funci√≥n de p√©rdida especificada\n",
        "lightning_model = AutoencoderLightning(\n",
        "    model=base_model,\n",
        "    learning_rate=cfg.trainer.learning_rate,\n",
        "    loss_function=cfg.trainer.loss_function,\n",
        "    scheduler_config=cfg.trainer.scheduler\n",
        ")\n",
        "\n",
        "print(f\"\\nArquitectura: {cfg.model.architecture}\")\n",
        "print(f\"Funci√≥n de p√©rdida: {cfg.trainer.loss_function}\")\n",
        "print(f\"Learning rate: {cfg.trainer.learning_rate}\")\n",
        "print(f\"Latent dim: {cfg.model.latent_dim}\")\n",
        "print(f\"Input channels: {cfg.model.input_channels}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idmV7qlxcq1q"
      },
      "source": [
        "## 3.1. Visualizaciones del Set de Validaci√≥n (Requisitos WandB)\n",
        "\n",
        "Esta secci√≥n genera las visualizaciones requeridas para WandB del set de validaci√≥n:\n",
        "\n",
        "1. **Reconstrucciones del set de validaci√≥n (16 im√°genes)**: Comparaci√≥n lado a lado de im√°genes originales vs reconstruidas\n",
        "2. **t-SNE del espacio latente**: Visualizaci√≥n 2D de c√≥mo el modelo organiza las im√°genes en el espacio latente\n",
        "\n",
        "**Nota**: Estas visualizaciones se registran autom√°ticamente en WandB.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLS4XR52cq1q"
      },
      "outputs": [],
      "source": [
        "# El val_loader ya fue creado en la celda anterior\n",
        "# Continuar con las visualizaciones del set de validaci√≥n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnJ94mtZcq1q"
      },
      "outputs": [],
      "source": [
        "# Visualizaci√≥n de reconstrucciones del set de validaci√≥n (16 im√°genes)lightning_model.model.eval()val_images = []val_reconstructions = []val_latent_vectors = []with torch.no_grad():    for batch_idx, images in enumerate(val_loader):        images = images.to(device)                # Obtener reconstrucciones        reconstructed = lightning_model.model(images)                # Extraer vectores latentes        if hasattr(lightning_model.model, 'encode'):            latent = lightning_model.model.encode(images)            # Para UNet, encode devuelve (latent, skip_connections), solo necesitamos latent            if isinstance(latent, tuple):                latent = latent[0]            # Aplanar el vector latente para t-SNE            latent_flat = latent.view(latent.size(0), -1)            val_latent_vectors.append(latent_flat.cpu().numpy())                # Guardar im√°genes para visualizaci√≥n (hasta 16)        if len(val_images) < 16:            remaining = 16 - len(val_images)            val_images.append(images[:remaining].cpu())            val_reconstructions.append(reconstructed[:remaining].cpu())                if len(val_images) >= 16:            break# Concatenar todas las im√°genesval_images = torch.cat(val_images[:16])[:16]val_reconstructions = torch.cat(val_reconstructions[:16])[:16]# Visualizar 16 reconstrucciones del set de validaci√≥nfig, axes = plt.subplots(4, 8, figsize=(20, 10))axes = axes.flatten()val_reconstruction_images = []for i in range(16):    # Imagen original    img = denormalize(val_images[i].clone())    axes[i*2].imshow(img.permute(1, 2, 0))    axes[i*2].set_title(f'Original {i+1}')    axes[i*2].axis('off')        # Reconstrucci√≥n    recon = denormalize(val_reconstructions[i].clone())    axes[i*2+1].imshow(recon.permute(1, 2, 0))    axes[i*2+1].set_title(f'Reconstrucci√≥n {i+1}')    axes[i*2+1].axis('off')        # Preparar para wandb    img_np = (img.permute(1, 2, 0).numpy() * 255).astype(np.uint8)    recon_np = (recon.permute(1, 2, 0).numpy() * 255).astype(np.uint8)    val_reconstruction_images.append(wandb.Image(img_np, caption=f\\\"Original Val {i+1}\\\"))    val_reconstruction_images.append(wandb.Image(recon_np, caption=f\\\"Reconstrucci√≥n Val {i+1}\\\"))plt.tight_layout()validation_recon_path = os.path.join(DRIVE_BASE_PATH, 'validation_reconstructions.png')plt.savefig(validation_recon_path)plt.show()# Loggear en wandbwandb.log({    \\\"val/reconstructions\\\": val_reconstruction_images,    \\\"val/reconstructions_grid\\\": wandb.Image(validation_recon_path)})print(\\\"Reconstrucciones del set de validaci√≥n guardadas en wandb\\\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CjOVtTJcq1r"
      },
      "outputs": [],
      "source": [
        "# Visualizaci√≥n t-SNE del espacio latente del set de validaci√≥nfrom sklearn.manifold import TSNE# Concatenar todos los vectores latentesif val_latent_vectors:    all_latent_vectors = np.concatenate(val_latent_vectors, axis=0)        print(f\\\"Forma de los vectores latentes: {all_latent_vectors.shape}\\\")    print(\\\"Aplicando t-SNE...\\\")        # Aplicar t-SNE (reducir a 2D para visualizaci√≥n)    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(all_latent_vectors)-1))    latent_2d = tsne.fit_transform(all_latent_vectors)        # Visualizar t-SNE    plt.figure(figsize=(10, 8))    plt.scatter(latent_2d[:, 0], latent_2d[:, 1], alpha=0.6, s=50)    plt.title('t-SNE del Espacio Latente (Set de Validaci√≥n)')    plt.xlabel('Componente t-SNE 1')    plt.ylabel('Componente t-SNE 2')    plt.grid(True, alpha=0.3)    plt.tight_layout()    tsne_path = os.path.join(DRIVE_BASE_PATH, 'tsne_latent_validation.png')    plt.savefig(tsne_path)    plt.show()        # Loggear en wandb    wandb.log({        \\\"val/tsne_latent\\\": wandb.Image(tsne_path)    })    print(\\\"t-SNE del espacio latente guardado en wandb\\\")else:    print(\\\"No se pudieron extraer vectores latentes. Verifica que el modelo tenga m√©todo encode().\\\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTAR15LgRfDg"
      },
      "source": [
        "## 3. Entrenamiento del Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsk-Pr-fRfDg"
      },
      "outputs": [],
      "source": [
        "# Entrenar modelo usando Pytorch Lightning Trainerfrom pytorch_lightning import Trainerfrom pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor# Configurar logger de WandB para Lightningwandb_logger = WandbLogger(    project=cfg.logger.project,    name=f\"{cfg.model.architecture}-{cfg.trainer.loss_function}-{SELECTED_CATEGORY}\",    config=OmegaConf.to_container(cfg, resolve=True))# Callbackscheckpoint_callback = ModelCheckpoint(    monitor='train/loss_epoch',    checkpoint_dir = os.path.join(DRIVE_BASE_PATH, 'checkpoints')os.makedirs(checkpoint_dir, exist_ok=True)dirpath=checkpoint_dir,    filename=f'{cfg.model.architecture}-{cfg.trainer.loss_function}-{{epoch:02d}}-{{train/loss_epoch:.4f}}',    save_top_k=1,    mode='min')lr_monitor = LearningRateMonitor(logging_interval='step')# Crear Trainer de Pytorch Lightningtrainer = Trainer(    max_epochs=cfg.trainer.max_epochs,    accelerator='auto',    devices=1,    logger=wandb_logger,    callbacks=[checkpoint_callback, lr_monitor],    log_every_n_steps=10,    enable_progress_bar=True)# Entrenar modeloprint(f'Iniciando entrenamiento con Pytorch Lightning...')print(f'Arquitectura: {cfg.model.architecture}')print(f'Funci√≥n de p√©rdida: {cfg.trainer.loss_function}')print(f'Learning rate: {cfg.trainer.learning_rate}')trainer.fit(lightning_model, train_loader)print('\\nEntrenamiento completado!')# Obtener p√©rdidas de entrenamiento del modelo Lightningtrain_losses = lightning_model.train_losses if hasattr(lightning_model, 'train_losses') else []# Obtener el modelo base entrenado para evaluaci√≥nmodel = lightning_model.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mazT5RORfDh"
      },
      "outputs": [],
      "source": [
        "# Visualizar curva de p√©rdidaplt.figure(figsize=(10, 6))plt.plot(train_losses)plt.title('Curva de P√©rdida de Entrenamiento')plt.xlabel('√âpoca')plt.ylabel('P√©rdida (MSE)')plt.grid(True)train_loss_path = os.path.join(DRIVE_BASE_PATH, 'train_loss_curve.png')plt.savefig(train_loss_path)plt.show()# Loggear la curva de p√©rdida en wandbwandb.log({\"train/loss_curve\": wandb.Image(train_loss_path)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXSHxPgWRfDh"
      },
      "source": [
        "## 4. Evaluaci√≥n y Detecci√≥n de Anomal√≠as\n",
        "\n",
        "En esta secci√≥n se eval√∫a el modelo entrenado en el set de prueba:\n",
        "\n",
        "1. **C√°lculo de scores de anomal√≠a**: Se usa el error de reconstrucci√≥n (MSE) como m√©trica\n",
        "2. **Selecci√≥n de im√°genes**: Se seleccionan 8 im√°genes buenas y 8 con anomal√≠as para visualizaci√≥n\n",
        "3. **C√°lculo de m√©tricas**: AUC-ROC y Average Precision\n",
        "4. **Visualizaci√≥n de curva ROC**: Gr√°fico de la curva ROC para evaluar el rendimiento\n",
        "\n",
        "**M√©tricas calculadas**:\n",
        "- **AUC-ROC**: √Årea bajo la curva ROC (mientras m√°s cercano a 1.0, mejor)\n",
        "- **Average Precision**: Precisi√≥n promedio (mientras m√°s cercano a 1.0, mejor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCx-UKUaRfDh"
      },
      "outputs": [],
      "source": [
        "def get_anomaly_labels(test_paths, category_path):\n",
        "    \"\"\"Obtiene las etiquetas de anomal√≠a (0=normal, 1=anomal√≠a)\"\"\"\n",
        "    labels = []\n",
        "    good_path = os.path.join(category_path, 'test', 'good')\n",
        "\n",
        "    for path in test_paths:\n",
        "        if good_path in path:\n",
        "            labels.append(0)  # Normal\n",
        "        else:\n",
        "            labels.append(1)  # Anomal√≠a\n",
        "\n",
        "    return np.array(labels)\n",
        "\n",
        "# Obtener etiquetas de prueba\n",
        "test_labels = get_anomaly_labels(test_paths, category_path)\n",
        "print(f'Im√°genes normales: {np.sum(test_labels == 0)}')\n",
        "print(f'Im√°genes con anomal√≠as: {np.sum(test_labels == 1)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVKJlE0TRfDh"
      },
      "outputs": [],
      "source": [
        "# Evaluar modelo en datos de prueba\n",
        "lightning_model.model.eval()\n",
        "anomaly_scores = []\n",
        "test_images_all = []\n",
        "test_reconstructions_all = []\n",
        "test_paths_all = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, images in enumerate(test_loader):\n",
        "        images = images.to(device)\n",
        "        reconstructed = lightning_model.model(images)\n",
        "\n",
        "        # Calcular error de reconstrucci√≥n (MSE) como score de anomal√≠a\n",
        "        mse = torch.mean((images - reconstructed) ** 2, dim=(1, 2, 3))\n",
        "        anomaly_scores.extend(mse.cpu().numpy())\n",
        "\n",
        "        # Guardar todas las im√°genes y reconstrucciones con sus rutas\n",
        "        batch_start = batch_idx * BATCH_SIZE\n",
        "        batch_paths = test_paths[batch_start:batch_start + len(images)]\n",
        "        test_images_all.append(images.cpu())\n",
        "        test_reconstructions_all.append(reconstructed.cpu())\n",
        "        test_paths_all.extend(batch_paths)\n",
        "\n",
        "anomaly_scores = np.array(anomaly_scores)\n",
        "print(f'Rango de scores: [{anomaly_scores.min():.4f}, {anomaly_scores.max():.4f}]')\n",
        "\n",
        "# Obtener etiquetas\n",
        "category_path = os.path.join(DATASET_PATH, SELECTED_CATEGORY)\n",
        "test_labels = get_anomaly_labels(test_paths_all, category_path)\n",
        "\n",
        "# Separar im√°genes buenas y con anomal√≠as\n",
        "good_indices = np.where(test_labels == 0)[0]\n",
        "anomaly_indices = np.where(test_labels == 1)[0]\n",
        "\n",
        "# Seleccionar 8 im√°genes buenas y 8 con anomal√≠as\n",
        "num_samples = 8\n",
        "selected_good_indices = good_indices[:num_samples] if len(good_indices) >= num_samples else good_indices\n",
        "selected_anomaly_indices = anomaly_indices[:num_samples] if len(anomaly_indices) >= num_samples else anomaly_indices\n",
        "\n",
        "# Concatenar todas las im√°genes\n",
        "all_test_images = torch.cat(test_images_all)\n",
        "all_test_reconstructions = torch.cat(test_reconstructions_all)\n",
        "\n",
        "# Seleccionar las 16 im√°genes (8 buenas + 8 con anomal√≠as)\n",
        "selected_indices = np.concatenate([selected_good_indices, selected_anomaly_indices])\n",
        "sample_images = all_test_images[selected_indices]\n",
        "sample_reconstructions = all_test_reconstructions[selected_indices]\n",
        "sample_labels = test_labels[selected_indices]\n",
        "\n",
        "print(f'Im√°genes seleccionadas: {len(selected_good_indices)} buenas + {len(selected_anomaly_indices)} con anomal√≠as = {len(sample_images)} total')\n",
        "\n",
        "# Loggear estad√≠sticas de scores en wandb\n",
        "wandb.log({\n",
        "    \"eval/min_score\": float(anomaly_scores.min()),\n",
        "    \"eval/max_score\": float(anomaly_scores.max()),\n",
        "    \"eval/mean_score\": float(anomaly_scores.mean()),\n",
        "    \"eval/std_score\": float(anomaly_scores.std())\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awWbAD11RfDh"
      },
      "outputs": [],
      "source": [
        "# Calcular m√©tricasauc_score = roc_auc_score(test_labels, anomaly_scores)ap_score = average_precision_score(test_labels, anomaly_scores)print(f'AUC-ROC: {auc_score:.4f}')print(f'Average Precision: {ap_score:.4f}')# Curva ROCfpr, tpr, thresholds = roc_curve(test_labels, anomaly_scores)plt.figure(figsize=(10, 6))plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.4f})')plt.plot([0, 1], [0, 1], 'k--', label='Random')plt.xlabel('False Positive Rate')plt.ylabel('True Positive Rate')plt.title('Curva ROC')plt.legend()plt.grid(True)roc_curve_path = os.path.join(DRIVE_BASE_PATH, 'roc_curve.png')plt.savefig(roc_curve_path)plt.show()# Loggear m√©tricas y curva ROC en wandbwandb.log({    \"eval/auc_roc\": auc_score,    \"eval/average_precision\": ap_score,    \"eval/roc_curve\": wandb.Image(roc_curve_path)})# Crear curva ROC interactiva en wandb# Nota: wandb.plot.roc_curve requiere que los scores sean probabilidades# Normalizamos los scores para que est√©n en [0, 1]normalized_scores = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min() + 1e-8)# wandb.plot.roc_curve necesita un formato espec√≠fico: y_probas debe ser una lista de arrays, uno por clase# Para binario, necesitamos [prob_clase_0, prob_clase_1] donde prob_clase_1 = normalized_scorestry:    wandb.log({        \"eval/roc_curve_interactive\": wandb.plot.roc_curve(test_labels,                                                            [1 - normalized_scores, normalized_scores],                                                            labels=[\"Normal\", \"Anomal√≠a\"],                                                            classes_to_plot=[1])    })except Exception as e:    print(f\"Error al crear curva ROC interactiva en wandb: {e}\")    print(\"La curva ROC est√°tica ya fue guardada correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hsPPd5fRfDh"
      },
      "source": [
        "## 5. Visualizaci√≥n de Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXM-O50-RfDi"
      },
      "outputs": [],
      "source": [
        "def denormalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):    \"\"\"Desnormaliza un tensor de imagen\"\"\"    for t, m, s in zip(tensor, mean, std):        t.mul_(s).add_(m)    return tensor.clamp_(0, 1)# Visualizar reconstrucciones del set de prueba (16 im√°genes: 8 buenas + 8 con anomal√≠as)fig, axes = plt.subplots(4, 8, figsize=(20, 10))axes = axes.flatten()test_reconstruction_images = []# Visualizar 8 im√°genes buenas primerofor i in range(8):    if i < len(sample_images):        idx = i        img = denormalize(sample_images[idx].clone())        recon = denormalize(sample_reconstructions[idx].clone())                # Imagen original        axes[i*2].imshow(img.permute(1, 2, 0))        axes[i*2].set_title(f'Buenas - Original {i+1}')        axes[i*2].axis('off')                # Reconstrucci√≥n        axes[i*2+1].imshow(recon.permute(1, 2, 0))        axes[i*2+1].set_title(f'Buenas - Reconstrucci√≥n {i+1}')        axes[i*2+1].axis('off')                # Preparar para wandb        img_np = (img.permute(1, 2, 0).numpy() * 255).astype(np.uint8)        recon_np = (recon.permute(1, 2, 0).numpy() * 255).astype(np.uint8)        test_reconstruction_images.append(wandb.Image(img_np, caption=f\"Buenas - Original {i+1}\"))        test_reconstruction_images.append(wandb.Image(recon_np, caption=f\"Buenas - Reconstrucci√≥n {i+1}\"))# Visualizar 8 im√°genes con anomal√≠asfor i in range(8):    idx = 8 + i    if idx < len(sample_images):        img = denormalize(sample_images[idx].clone())        recon = denormalize(sample_reconstructions[idx].clone())                # Imagen original        axes[16 + i*2].imshow(img.permute(1, 2, 0))        axes[16 + i*2].set_title(f'Anomal√≠a - Original {i+1}')        axes[16 + i*2].axis('off')                # Reconstrucci√≥n        axes[16 + i*2+1].imshow(recon.permute(1, 2, 0))        axes[16 + i*2+1].set_title(f'Anomal√≠a - Reconstrucci√≥n {i+1}')        axes[16 + i*2+1].axis('off')                # Preparar para wandb        img_np = (img.permute(1, 2, 0).numpy() * 255).astype(np.uint8)        recon_np = (recon.permute(1, 2, 0).numpy() * 255).astype(np.uint8)        test_reconstruction_images.append(wandb.Image(img_np, caption=f\"Anomal√≠a - Original {i+1}\"))        test_reconstruction_images.append(wandb.Image(recon_np, caption=f\"Anomal√≠a - Reconstrucci√≥n {i+1}\"))plt.tight_layout()test_recon_path = os.path.join(DRIVE_BASE_PATH, 'test_reconstructions.png')plt.savefig(test_recon_path)plt.show()# Loggear reconstrucciones del set de prueba en wandbwandb.log({    \"test/reconstructions\": test_reconstruction_images,    \"test/reconstructions_grid\": wandb.Image(test_recon_path)})print(\"Reconstrucciones del set de prueba (16 im√°genes: 8 buenas + 8 con anomal√≠as) guardadas en wandb\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RTI1Qy9RfDi"
      },
      "outputs": [],
      "source": [
        "# Visualizar distribuci√≥n de scoresnormal_scores = anomaly_scores[test_labels == 0]anomaly_scores_plot = anomaly_scores[test_labels == 1]plt.figure(figsize=(12, 5))plt.subplot(1, 2, 1)plt.hist(normal_scores, bins=50, alpha=0.7, label='Normal', color='green')plt.hist(anomaly_scores_plot, bins=50, alpha=0.7, label='Anomal√≠a', color='red')plt.xlabel('Anomaly Score (MSE)')plt.ylabel('Frecuencia')plt.title('Distribuci√≥n de Scores de Anomal√≠a')plt.legend()plt.grid(True, alpha=0.3)plt.subplot(1, 2, 2)plt.boxplot([normal_scores, anomaly_scores_plot], tick_labels=['Normal', 'Anomal√≠a'])plt.ylabel('Anomaly Score (MSE)')plt.title('Boxplot de Scores')plt.grid(True, alpha=0.3)plt.tight_layout()score_dist_path = os.path.join(DRIVE_BASE_PATH, 'score_distribution.png')plt.savefig(score_dist_path)plt.show()# Loggear distribuci√≥n de scores en wandbwandb.log({    \"eval/score_distribution\": wandb.Image(score_dist_path),    \"eval/normal_scores_mean\": float(normal_scores.mean()),    \"eval/normal_scores_std\": float(normal_scores.std()),    \"eval/anomaly_scores_mean\": float(anomaly_scores_plot.mean()),    \"eval/anomaly_scores_std\": float(anomaly_scores_plot.std())})# Crear histograma interactivo en wandbwandb.log({    \"eval/scores_histogram\": wandb.Histogram(anomaly_scores, num_bins=50)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNlxgWWIRfDi"
      },
      "outputs": [],
      "source": [
        "# Encontrar mejores y peores reconstrucciones\n",
        "sorted_indices = np.argsort(anomaly_scores)\n",
        "\n",
        "print(\"Top 5 im√°genes con menor error (m√°s normales):\")\n",
        "for idx in sorted_indices[:5]:\n",
        "    print(f\"  {test_paths[idx]} - Score: {anomaly_scores[idx]:.4f}\")\n",
        "\n",
        "print(\"\\nTop 5 im√°genes con mayor error (m√°s an√≥malas):\")\n",
        "for idx in sorted_indices[-5:]:\n",
        "    print(f\"  {test_paths[idx]} - Score: {anomaly_scores[idx]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZXwe2LSRfDi"
      },
      "source": [
        "## 6. Guardar Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kH3w1fURfDi"
      },
      "outputs": [],
      "source": [
        "# Guardar modelo entrenadomodel_save_path = os.path.join(DRIVE_BASE_PATH, 'modelo_autoencoder.pth')torch.save({    'model_state_dict': lightning_model.model.state_dict(),    'optimizer_state_dict': lightning_model.optimizers().state_dict(),    'train_losses': train_losses,    'auc_score': auc_score,    'ap_score': ap_score}, model_save_path)print(f'Modelo guardado en: {model_save_path}')# Guardar modelo en wandbwandb.save(model_save_path)# Finalizar wandb runwandb.finish()print(\"Weights & Biases finalizado. Revisa tus m√©tricas en https://wandb.ai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRXYbGMNRfDi"
      },
      "source": [
        "## Notas Finales\n",
        "\n",
        "- El modelo ha sido entrenado solo con im√°genes normales (good)\n",
        "- Las anomal√≠as se detectan mediante el error de reconstrucci√≥n\n",
        "- Puedes ajustar el umbral de detecci√≥n seg√∫n tus necesidades\n",
        "- Para cargar el modelo guardado, usa: `torch.load(model_save_path)`\n",
        "\n",
        "### Weights & Biases\n",
        "\n",
        "- Todas las m√©tricas de entrenamiento y evaluaci√≥n se registran autom√°ticamente en wandb\n",
        "- Revisa tus resultados en: https://wandb.ai\n",
        "- El proyecto se llama: `tarea05-anomaly-detection`\n",
        "- Cada run se identifica por la categor√≠a utilizada\n",
        "\n",
        "### M√©tricas Registradas\n",
        "\n",
        "- **Entrenamiento**: p√©rdida por batch, p√©rdida por √©poca, learning rate\n",
        "- **Evaluaci√≥n**: AUC-ROC, Average Precision, estad√≠sticas de scores\n",
        "- **Visualizaciones**: curva ROC, reconstrucciones, distribuci√≥n de scores\n",
        "- **Modelo**: se guarda autom√°ticamente en wandb\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}